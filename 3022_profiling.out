Switching to group 'render' and re-executing...
True
Checking GPU Availability...
Torch version: 2.9.1+rocm7.1.1.git351ff442
Is ROCm/CUDA available?: True
Device count: 1
/var/spool/slurm/slurmd/job03022/slurm_script: line 44: module: command not found
-------------------------------------------
Processing dataset: unitree_z1_stackbox
2026-02-08 15:49:11.680816: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-02-08 15:49:12.361461: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2026-02-08 15:49:12.366349: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2026-02-08 15:49:12.378929: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2026-02-08 15:49:12.448676: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2026-02-08 15:49:14.437001: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[rank: 0] Global seed set to 123
Nvidia GPU detected!
Total visible GPUs: 1
--- GPU 0 ---
Name: AMD Radeon PRO W7900D
Total memory: 49136 MB
it's find only 1 gpus can't do multi gpu
still run it's any ways
INFO:root:[INFO] Start Inference
INFO:root:init valueable: 0.008861s
/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
INFO:mainlogger:LatentVisualDiffusion: Running in v-prediction mode
WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.3.1+cu121 with CUDA 1201 (you have 2.9.1+rocm7.1.1.git351ff442)
    Python  3.10.14 (you have 3.10.18)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/xformers/ops/swiglu_op.py:128: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(cls, ctx, x, w1, b1, w2, b2, w3, b3):
/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/xformers/ops/swiglu_op.py:149: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(cls, ctx, dx5):
INFO:unifolm_wma.models.diffusion_head.conditional_unet1d:number of parameters: 5.010531e+08
INFO:unifolm_wma.models.diffusion_head.conditional_unet1d:number of parameters: 5.010531e+08
AE working on z of shape (1, 4, 32, 32) = 4096 dimensions.
INFO:root:Loaded ViT-H-14 model config.
INFO:root:Loaded ViT-H-14 model config.
/mnt/ASC1664/unifolm-wma-0-dual_run_workspace/ASC26-Embodied-World-Model-Optimization/ckpts/unifolm_wma_dual.ckpt
INFO:root:load models: 37.423180s
>>> model checkpoint loaded.
>>> Load pre-trained model ...
INFO:root:load model checkpoint: 22.116448s
INFO:root:***** Configing Data *****
>>> unitree_z1_stackbox: 1 data samples loaded.
>>> unitree_z1_stackbox: data stats loaded.
>>> unitree_z1_stackbox: normalizer initiated.
>>> unitree_z1_dual_arm_stackbox: 1 data samples loaded.
>>> unitree_z1_dual_arm_stackbox: data stats loaded.
>>> unitree_z1_dual_arm_stackbox: normalizer initiated.
>>> unitree_z1_dual_arm_stackbox_v2: 1 data samples loaded.
>>> unitree_z1_dual_arm_stackbox_v2: data stats loaded.
>>> unitree_z1_dual_arm_stackbox_v2: normalizer initiated.
>>> unitree_z1_dual_arm_cleanup_pencils: 1 data samples loaded.
>>> unitree_z1_dual_arm_cleanup_pencils: data stats loaded.
>>> unitree_z1_dual_arm_cleanup_pencils: normalizer initiated.
>>> unitree_g1_pack_camera: 1 data samples loaded.
>>> unitree_g1_pack_camera: data stats loaded.
>>> unitree_g1_pack_camera: normalizer initiated.
>>> Dataset is successfully loaded ...
INFO:root:load data: 0.205550s
>>> Generate 16 frames under each generation ...
INFO:root:set up data: 0.000029s
INFO:root:[INFO] Start running Inference
INFO:root:get_init_frame_path: 0.000048s
INFO:root:mkdir: 0.002775s
INFO:root:get_transition_path: 0.000017s
DEBUG:h5py._conv:Creating converter from 3 to 5
INFO:root:load file h5py: 0.008181s
INFO:root:[INFO] start running on loop frame_stride
INFO:root:mkdir => save dir: 0.001473s
INFO:root:init value: 0.000028s
DEBUG:PIL.PngImagePlugin:STREAM b'IHDR' 16 13
DEBUG:PIL.PngImagePlugin:STREAM b'IDAT' 41 65536
INFO:root:PIL open image : 0.017629s
INFO:root:create action & state: 0.000221s
INFO:root:normalize action - state: 0.000595s
INFO:root:spatial_transform: 0.000862s
INFO:root:prepare_init_input : 0.032367s
INFO:root:init observation: 0.003864s
INFO:root:init condition input w/ populate_queues: 0.000018s
INFO:root:[INFO] start running on loop n_iter
INFO:root:[INFO] start 1/12 n_iter (start with idx:1)
INFO:root:get decision model observation: 0.027942s
>>> Step 1: generating actions ...
INFO:root:[INFO] Step 1: generating actions ...
INFO:root:[INFO] IN image_guided_synthesis_sim_mode function
INFO:root:init model & noise: 0.000349s
INFO:root:permute image: 0.000012s
INFO:root:rearrange image: 0.002109s
/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/nn/functional.py:6487: UserWarning: Flash Efficient attention on Current AMD GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:309.)
  attn_output = scaled_dot_product_attention(
/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/nn/functional.py:6487: UserWarning: Mem Efficient attention on Current AMD GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:360.)
  attn_output = scaled_dot_product_attention(
INFO:root:CLIP Embedded Image: 0.838461s
INFO:root:Projector Image model: 0.003849s
INFO:root:[INFO] get_latent_z function
INFO:root:get_latent_z => rearrange video: 0.000105s
INFO:root:get_latent_z => encode_first_stage: 0.136870s
INFO:root:get_latent_z => rearrange z: 0.000112s
INFO:root:conditioning_key -> repeat: 0.000121s
INFO:root:Embedded Prompt: 0.028886s
INFO:root:Projector state: 0.000243s
INFO:root:Projector action: 0.000190s
INFO:root:[INFO] Apply model logic
INFO:root:[INFO] DDIMSampler.sample
INFO:root:prepare input of ddim_sampling: 0.020379s
INFO:root:prepare input of feeding: 0.005862s
INFO:root:[INFO] ========= Iteration 50 in total =========
INFO:root:[INFO] ========= Iteration 0/50 =========
INFO:root:[INFO] p_sample_ddim
INFO:root:[INFO] unconditional_conditioning
INFO:root:[INFO] apply_model
INFO:root:[INFO] apply model on WMAModel
INFO:root:predict_eps_from_z_and_v: 0.010521s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.000556s
INFO:root:pred_x0 : 0.000090s
INFO:root:use_dynamic_rescale: 0.000274s
INFO:root:tensor sqrt.quantize: 0.000116s
INFO:root:noise_like: 0.000061s
INFO:root:math apply: 0.000037s
INFO:root:[INFO] ========= Iteration 1/50 =========
INFO:root:[INFO] p_sample_ddim
INFO:root:[INFO] unconditional_conditioning
INFO:root:[INFO] apply_model
INFO:root:[INFO] apply model on WMAModel
INFO:root:predict_eps_from_z_and_v: 0.000069s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.001620s
INFO:root:pred_x0 : 0.000087s
INFO:root:use_dynamic_rescale: 0.000234s
INFO:root:tensor sqrt.quantize: 0.000079s
INFO:root:noise_like: 0.000062s
INFO:root:math apply: 0.000040s
INFO:root:[INFO] ========= Iteration 2/50 =========
INFO:root:[INFO] p_sample_ddim
INFO:root:[INFO] unconditional_conditioning
INFO:root:[INFO] apply_model
INFO:root:[INFO] apply model on WMAModel
INFO:root:predict_eps_from_z_and_v: 0.000088s
INFO:root:alphas_cumprod: 0.000003s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.004708s
INFO:root:pred_x0 : 0.000093s
INFO:root:use_dynamic_rescale: 0.000245s
INFO:root:tensor sqrt.quantize: 0.000106s
INFO:root:noise_like: 0.000068s
INFO:root:math apply: 0.000040s
INFO:root:[INFO] ========= Iteration 3/50 =========
INFO:root:[INFO] p_sample_ddim
INFO:root:[INFO] unconditional_conditioning
INFO:root:[INFO] apply_model
INFO:root:[INFO] apply model on WMAModel
INFO:root:predict_eps_from_z_and_v: 0.000074s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.001223s
INFO:root:pred_x0 : 0.000088s
INFO:root:use_dynamic_rescale: 0.000238s
INFO:root:tensor sqrt.quantize: 0.000086s
INFO:root:noise_like: 0.000062s
INFO:root:math apply: 0.000041s
INFO:root:[INFO] ========= Iteration 4/50 =========
INFO:root:[INFO] p_sample_ddim
INFO:root:[INFO] unconditional_conditioning
INFO:root:[INFO] apply_model
INFO:root:[INFO] apply model on WMAModel
INFO:root:predict_eps_from_z_and_v: 0.000071s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.004550s
INFO:root:pred_x0 : 0.000092s
INFO:root:use_dynamic_rescale: 0.000233s
INFO:root:tensor sqrt.quantize: 0.000082s
INFO:root:noise_like: 0.000063s
INFO:root:math apply: 0.000052s
INFO:root:[INFO] ========= Iteration 5/50 =========
INFO:root:[INFO] p_sample_ddim
INFO:root:[INFO] unconditional_conditioning
INFO:root:[INFO] apply_model
INFO:root:[INFO] apply model on WMAModel
INFO:root:predict_eps_from_z_and_v: 0.000080s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.002678s
INFO:root:pred_x0 : 0.000090s
INFO:root:use_dynamic_rescale: 0.000235s
INFO:root:tensor sqrt.quantize: 0.000083s
INFO:root:noise_like: 0.000064s
INFO:root:math apply: 0.000040s
INFO:root:[INFO] ========= Iteration 6/50 =========
INFO:root:[INFO] p_sample_ddim
INFO:root:[INFO] unconditional_conditioning
INFO:root:[INFO] apply_model
INFO:root:[INFO] apply model on WMAModel
INFO:root:predict_eps_from_z_and_v: 0.000076s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.000303s
INFO:root:pred_x0 : 0.000110s
INFO:root:use_dynamic_rescale: 0.000234s
INFO:root:tensor sqrt.quantize: 0.000170s
INFO:root:noise_like: 0.000062s
INFO:root:math apply: 0.000039s
INFO:root:[INFO] ========= Iteration 7/50 =========
INFO:root:[INFO] p_sample_ddim
INFO:root:[INFO] unconditional_conditioning
INFO:root:[INFO] apply_model
INFO:root:[INFO] apply model on WMAModel
slurmstepd-wx-ms-w7900d-0032: error: *** JOB 3022 ON wx-ms-w7900d-0032 CANCELLED AT 2026-02-08T15:50:43 ***
