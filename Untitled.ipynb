{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f02396-cad9-400c-a92b-eacfba54edfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permission needed to access required GPU device node(s):\n",
      "  - /dev/dri/card0: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card1: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card2: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card3: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card4: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card5: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card6: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card7: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card8: Permission denied; owner=root(0):video(44);\n",
      "\n",
      "You can try:\n",
      "  • Add your user to the group that owns these devices:\n",
      "      sudo usermod -aG <group> \"$USER\"\n",
      "\n",
      "+------------------------------------------------------------------------------+\n",
      "| AMD-SMI 26.2.0+021c61fc      amdgpu version: 6.16.6   ROCm version: 7.1.1    |\n",
      "| VBIOS version: 00162356                                                      |\n",
      "| Platform: Linux Baremetal                                                    |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| BDF                        GPU-Name | Mem-Uti   Temp   UEC       Power-Usage |\n",
      "| GPU  HIP-ID  OAM-ID  Partition-Mode | GFX-Uti    Fan               Mem-Usage |\n",
      "|=====================================+========================================|\n",
      "| 0000:03:00.0  AMD Radeon PRO W7900D | 5 %      32 °C   0            45/241 W |\n",
      "|   0       0     N/A             N/A | 16 %    20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:23:00.0  AMD Radeon PRO W7900D | 1 %      32 °C   0            15/241 W |\n",
      "|   1       1     N/A             N/A | 3 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:43:00.0  AMD Radeon PRO W7900D | 0 %      32 °C   0             9/241 W |\n",
      "|   2       2     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:63:00.0  AMD Radeon PRO W7900D | 0 %      29 °C   0            20/241 W |\n",
      "|   3       3     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:83:00.0  AMD Radeon PRO W7900D | 0 %      32 °C   0            14/241 W |\n",
      "|   4       4     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:a3:00.0  AMD Radeon PRO W7900D | 0 %      32 °C   0            15/241 W |\n",
      "|   5       5     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:c3:00.0  AMD Radeon PRO W7900D | 0 %      31 °C   0            17/241 W |\n",
      "|   6       6     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:e3:00.0  AMD Radeon PRO W7900D | 0 %      32 °C   0            10/241 W |\n",
      "|   7       7     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "+-------------------------------------+----------------------------------------+\n",
      "+------------------------------------------------------------------------------+\n",
      "| Processes:                                                                   |\n",
      "|  GPU        PID  Process Name          GTT_MEM  VRAM_MEM  MEM_USAGE     CU % |\n",
      "|==============================================================================|\n",
      "|    0     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    1     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    2     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    3     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    4     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    5     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    6     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    7     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "+------------------------------------------------------------------------------+\n",
      "Process Name may require elevated permissions.\n"
     ]
    }
   ],
   "source": [
    "!amd-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670a0253-4c30-482d-9ad2-4765622d6385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nvidia GPU detected!\n",
      "Total visible GPUs: 1\n",
      "--- GPU 0 ---\n",
      "Name: AMD Radeon PRO W7900D\n",
      "Total memory: 49136 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Nvidia GPU detected!\")\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Total visible GPUs: {gpu_count}\")\n",
    "\n",
    "    for i in range(gpu_count):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"--- GPU {i} ---\")\n",
    "        print(f\"Name: {props.name}\")\n",
    "        print(f\"Total memory: {props.total_memory / (1024**2):.0f} MB\")\n",
    "        # Add more properties if needed\n",
    "else:\n",
    "    print(\"No Nvidia GPU visible to PyTorch, or using CPU only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f317cde1-9e25-4152-912e-edf0c2a51907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18624955-6d4c-4eda-ace7-1283db14625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.layer1 = self._make_layer(BasicBlock, 64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b45cdb27-e7d8-4112-b1a7-49c0c80ffdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ResNet18(num_classes = 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "932a0633-cbb9-445a-a1db-c0564785a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.rand(16,3,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "443f1236-b450-42d4-b284-ba25b717f627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permission needed to access required GPU device node(s):\n",
      "  - /dev/dri/card0: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card1: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card2: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card3: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card4: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card5: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card6: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card7: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card8: Permission denied; owner=root(0):video(44);\n",
      "\n",
      "You can try:\n",
      "  • Add your user to the group that owns these devices:\n",
      "      sudo usermod -aG <group> \"$USER\"\n",
      "\n",
      "+------------------------------------------------------------------------------+\n",
      "| AMD-SMI 26.2.0+021c61fc      amdgpu version: 6.16.6   ROCm version: 7.1.1    |\n",
      "| VBIOS version: 00162356                                                      |\n",
      "| Platform: Linux Baremetal                                                    |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| BDF                        GPU-Name | Mem-Uti   Temp   UEC       Power-Usage |\n",
      "| GPU  HIP-ID  OAM-ID  Partition-Mode | GFX-Uti    Fan               Mem-Usage |\n",
      "|=====================================+========================================|\n",
      "| 0000:03:00.0  AMD Radeon PRO W7900D | 0 %      29 °C   0            12/241 W |\n",
      "|   0       0     N/A             N/A | 0 %     20.0 %            231/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:23:00.0  AMD Radeon PRO W7900D | 0 %      30 °C   0             9/241 W |\n",
      "|   1       1     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:43:00.0  AMD Radeon PRO W7900D | 0 %      30 °C   0             8/241 W |\n",
      "|   2       2     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:63:00.0  AMD Radeon PRO W7900D | 0 %      29 °C   0            20/241 W |\n",
      "|   3       3     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:83:00.0  AMD Radeon PRO W7900D | 0 %      28 °C   0            11/241 W |\n",
      "|   4       4     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:a3:00.0  AMD Radeon PRO W7900D | 0 %      30 °C   0            18/241 W |\n",
      "|   5       5     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:c3:00.0  AMD Radeon PRO W7900D | 0 %      30 °C   0            14/241 W |\n",
      "|   6       6     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:e3:00.0  AMD Radeon PRO W7900D | 0 %      30 °C   0            10/241 W |\n",
      "|   7       7     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "+-------------------------------------+----------------------------------------+\n",
      "+------------------------------------------------------------------------------+\n",
      "| Processes:                                                                   |\n",
      "|  GPU        PID  Process Name          GTT_MEM  VRAM_MEM  MEM_USAGE     CU % |\n",
      "|==============================================================================|\n",
      "|    0     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    0    3490236  python3.10             2.0 MB  199.6 MB   204.1 MB  N/A     |\n",
      "|    1     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    1    3490236  python3.10             2.0 MB   58.6 KB      0.0 B  N/A     |\n",
      "|    2     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    2    3490236  python3.10             2.0 MB   58.6 KB      0.0 B  N/A     |\n",
      "|    3     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    3    3490236  python3.10             2.0 MB   58.6 KB      0.0 B  N/A     |\n",
      "|    4     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    4    3490236  python3.10             2.0 MB   58.6 KB      0.0 B  N/A     |\n",
      "|    5     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    5    3490236  python3.10             2.0 MB   58.6 KB      0.0 B  N/A     |\n",
      "|    6     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    6    3490236  python3.10             2.0 MB   58.6 KB      0.0 B  N/A     |\n",
      "|    7     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    7    3490236  python3.10             2.0 MB   58.6 KB      0.0 B  N/A     |\n",
      "+------------------------------------------------------------------------------+\n",
      "Process Name may require elevated permissions.\n"
     ]
    }
   ],
   "source": [
    "!amd-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b59b3e8-7b57-45a9-94d8-78490b9f2ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING: AMD GPU device(s) is/are in a low-power state. Check power control/runtime_status\n",
      "\n",
      "======================================== ROCm System Management Interface ========================================\n",
      "================================================== Concise Info ==================================================\n",
      "Device  Node  IDs              Temp    Power  Partitions          SCLK  MCLK   Fan    Perf  PwrCap  VRAM%  GPU%  \n",
      "\u001b[3m              (DID,     GUID)  (Edge)  (Avg)  (Mem, Compute, ID)                                                 \u001b[0m\n",
      "==================================================================================================================\n",
      "0       2     0x744b,   6853   23.0°C  15.0W  N/A, N/A, 0         0Mhz  96Mhz  20.0%  auto  241.0W  0%     0%    \n",
      "1       3     0x744b,   49884  24.0°C  14.0W  N/A, N/A, 0         0Mhz  96Mhz  20.0%  auto  241.0W  0%     0%    \n",
      "2       4     0x744b,   60148  23.0°C  14.0W  N/A, N/A, 0         0Mhz  96Mhz  20.0%  auto  241.0W  0%     0%    \n",
      "3       5     0x744b,   13037  24.0°C  12.0W  N/A, N/A, 0         0Mhz  96Mhz  20.0%  auto  241.0W  0%     0%    \n",
      "4       6     0x744b,   47780  22.0°C  12.0W  N/A, N/A, 0         0Mhz  96Mhz  20.0%  auto  241.0W  0%     0%    \n",
      "5       7     0x744b,   25277  22.0°C  9.0W   N/A, N/A, 0         0Mhz  96Mhz  20.0%  auto  241.0W  0%     0%    \n",
      "6       8     0x744b,   19093  23.0°C  9.0W   N/A, N/A, 0         0Mhz  96Mhz  20.0%  auto  241.0W  0%     0%    \n",
      "7       9     0x744b,   37516  24.0°C  9.0W   N/A, N/A, 0         0Mhz  96Mhz  20.0%  auto  241.0W  0%     0%    \n",
      "==================================================================================================================\n",
      "============================================== End of ROCm SMI Log ===============================================\n"
     ]
    }
   ],
   "source": [
    "!rocm-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60fff877-8250-4c6a-960d-d215126b4f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.to(device)\n",
    "output = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d145a11f-7473-4e02-906f-1671ffc5a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98e2ecae-1f96-4871-aa1b-7b693068a85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permission needed to access required GPU device node(s):\n",
      "  - /dev/dri/card0: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card1: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card2: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card3: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card4: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card5: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card6: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card7: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card8: Permission denied; owner=root(0):video(44);\n",
      "\n",
      "You can try:\n",
      "  • Add your user to the group that owns these devices:\n",
      "      sudo usermod -aG <group> \"$USER\"\n",
      "\n",
      "+------------------------------------------------------------------------------+\n",
      "| AMD-SMI 26.2.0+021c61fc      amdgpu version: 6.16.6   ROCm version: 7.1.1    |\n",
      "| VBIOS version: 00162356                                                      |\n",
      "| Platform: Linux Baremetal                                                    |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| BDF                        GPU-Name | Mem-Uti   Temp   UEC       Power-Usage |\n",
      "| GPU  HIP-ID  OAM-ID  Partition-Mode | GFX-Uti    Fan               Mem-Usage |\n",
      "|=====================================+========================================|\n",
      "| 0000:03:00.0  AMD Radeon PRO W7900D | 0 %      30 °C   0            24/241 W |\n",
      "|   0       0     N/A             N/A | 5 %     20.78             711/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:23:00.0  AMD Radeon PRO W7900D | 0 %      30 °C   0            14/241 W |\n",
      "|   1       1     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:43:00.0  AMD Radeon PRO W7900D | 0 %      30 °C   0            14/241 W |\n",
      "|   2       2     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:63:00.0  AMD Radeon PRO W7900D | 0 %      29 °C   0            11/241 W |\n",
      "|   3       3     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:83:00.0  AMD Radeon PRO W7900D | 0 %      28 °C   0            17/241 W |\n",
      "|   4       4     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:a3:00.0  AMD Radeon PRO W7900D | 0 %      30 °C   0            20/241 W |\n",
      "|   5       5     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:c3:00.0  AMD Radeon PRO W7900D | 0 %      30 °C   0             9/241 W |\n",
      "|   6       6     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:e3:00.0  AMD Radeon PRO W7900D | 0 %      30 °C   0             9/241 W |\n",
      "|   7       7     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "+-------------------------------------+----------------------------------------+\n",
      "+------------------------------------------------------------------------------+\n",
      "| Processes:                                                                   |\n",
      "|  GPU        PID  Process Name          GTT_MEM  VRAM_MEM  MEM_USAGE     CU % |\n",
      "|==============================================================================|\n",
      "|    0     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    0    3490236  python3.10             2.0 MB  668.9 MB   684.5 MB  N/A     |\n",
      "|    1     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    1    3490236  python3.10             2.0 MB   58.6 KB      0.0 B  N/A     |\n",
      "|    2     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    2    3490236  python3.10             2.0 MB   58.6 KB      0.0 B  N/A     |\n",
      "|    3     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    3    3490236  python3.10             2.0 MB   58.6 KB      0.0 B  N/A     |\n",
      "|    4     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    4    3490236  python3.10             2.0 MB   58.6 KB      0.0 B  N/A     |\n",
      "|    5     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    5    3490236  python3.10             2.0 MB   58.6 KB      0.0 B  N/A     |\n",
      "|    6     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    6    3490236  python3.10             2.0 MB   58.6 KB      0.0 B  N/A     |\n",
      "|    7     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    7    3490236  python3.10             2.0 MB   58.6 KB      0.0 B  N/A     |\n",
      "+------------------------------------------------------------------------------+\n",
      "Process Name may require elevated permissions.\n",
      "\n",
      "\n",
      "WARNING: AMD GPU device(s) is/are in a low-power state. Check power control/runtime_status\n",
      "\n",
      "======================================== ROCm System Management Interface ========================================\n",
      "================================================== Concise Info ==================================================\n",
      "Device  Node  IDs              Temp    Power  Partitions          SCLK  MCLK   Fan    Perf  PwrCap  VRAM%  GPU%  \n",
      "\u001b[3m              (DID,     GUID)  (Edge)  (Avg)  (Mem, Compute, ID)                                                 \u001b[0m\n",
      "==================================================================================================================\n",
      "0       2     0x744b,   6853   24.0°C  13.0W  N/A, N/A, 0         0Mhz  96Mhz  20.0%  auto  241.0W  1%     0%    \n",
      "1       3     0x744b,   49884  24.0°C  10.0W  N/A, N/A, 0         0Mhz  96Mhz  20.0%  auto  241.0W  0%     0%    \n",
      "2       4     0x744b,   60148  23.0°C  14.0W  N/A, N/A, 0         0Mhz  96Mhz  20.0%  auto  241.0W  0%     0%    \n",
      "3       5     0x744b,   13037  24.0°C  15.0W  N/A, N/A, 0         0Mhz  96Mhz  20.0%  auto  241.0W  0%     0%    \n",
      "4       6     0x744b,   47780  22.0°C  11.0W  N/A, N/A, 0         0Mhz  96Mhz  20.0%  auto  241.0W  0%     0%    \n",
      "5       7     0x744b,   25277  22.0°C  14.0W  N/A, N/A, 0         0Mhz  96Mhz  20.0%  auto  241.0W  0%     0%    \n",
      "6       8     0x744b,   19093  23.0°C  12.0W  N/A, N/A, 0         0Mhz  96Mhz  20.0%  auto  241.0W  0%     0%    \n",
      "7       9     0x744b,   37516  24.0°C  11.0W  N/A, N/A, 0         0Mhz  96Mhz  20.0%  auto  241.0W  0%     0%    \n",
      "==================================================================================================================\n",
      "============================================== End of ROCm SMI Log ===============================================\n"
     ]
    }
   ],
   "source": [
    "!amd-smi\n",
    "!rocm-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e3a7d2-f702-47ea-98e1-6a319240fd85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f45e47d0-d0d5-4f36-a7fe-134ba5065d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Nvidia GPU detected!\n",
      "PyTorch CUDA version: None\n",
      "CUDA runtime available: True\n",
      "==================================================\n",
      "Total visible GPUs: 1\n",
      "\n",
      "--- GPU 0 ---\n",
      "Name: AMD Radeon PRO W7900D\n",
      "Compute capability: 11.0\n",
      "Total memory: 49136 MB\n",
      "Multiprocessors (SMs): 48\n",
      "Max threads per SM: 2048\n",
      "Warp size: 32\n",
      "Memory allocated: 406.5 MB\n",
      "Memory reserved : 414.0 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def bytes_to_mb(x):\n",
    "    return x / (1024 ** 2)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"✅ Nvidia GPU detected!\")\n",
    "    print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"CUDA runtime available: {torch.cuda.is_initialized()}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Total visible GPUs: {gpu_count}\\n\")\n",
    "\n",
    "    for i in range(gpu_count):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "\n",
    "        print(f\"--- GPU {i} ---\")\n",
    "        print(f\"Name: {props.name}\")\n",
    "        print(f\"Compute capability: {props.major}.{props.minor}\")\n",
    "        print(f\"Total memory: {bytes_to_mb(props.total_memory):.0f} MB\")\n",
    "\n",
    "        # Architecture details\n",
    "        print(f\"Multiprocessors (SMs): {props.multi_processor_count}\")\n",
    "        print(f\"Max threads per SM: {props.max_threads_per_multi_processor}\")\n",
    "        # print(f\"Max threads per block: {props.max_threads_per_block}\")\n",
    "        print(f\"Warp size: {props.warp_size}\")\n",
    "\n",
    "        # Clock rates\n",
    "        # print(f\"GPU clock rate: {props.clock_rate / 1000:.1f} MHz\")\n",
    "        # print(f\"Memory clock rate: {props.memory_clock_rate / 1000:.1f} MHz\")\n",
    "\n",
    "        # Memory system\n",
    "        # print(f\"Memory bus width: {props.memory_bus_width} bits\")\n",
    "        # print(f\"L2 cache size: {props.l2_cache_size / 1024:.0f} KB\")\n",
    "\n",
    "        # Current memory usage (PyTorch-side)\n",
    "        torch.cuda.set_device(i)\n",
    "        print(f\"Memory allocated: {bytes_to_mb(torch.cuda.memory_allocated(i)):.1f} MB\")\n",
    "        print(f\"Memory reserved : {bytes_to_mb(torch.cuda.memory_reserved(i)):.1f} MB\")\n",
    "\n",
    "        print()\n",
    "\n",
    "else:\n",
    "    print(\"❌ No Nvidia GPU visible to PyTorch (CPU-only mode).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "989cccec-46d2-4399-8244-fd8cb6977442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Nvidia GPU detected!\n",
      "PyTorch CUDA version: None\n",
      "CUDA runtime available: True\n",
      "==================================================\n",
      "Total visible GPUs: 1\n",
      "\n",
      "--- GPU 0 ---\n",
      "Name: AMD Radeon PRO W7900D\n",
      "Compute capability: 11.0\n",
      "Total memory: 49136 MB\n",
      "Multiprocessors (SMs): 48\n",
      "Max threads per SM: 2048\n",
      "Warp size: 32\n",
      "Memory allocated: 406.5 MB\n",
      "Memory reserved : 414.0 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def bytes_to_mb(x):\n",
    "    return x / (1024 ** 2)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"✅ Nvidia GPU detected!\")\n",
    "    print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"CUDA runtime available: {torch.cuda.is_initialized()}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Total visible GPUs: {gpu_count}\\n\")\n",
    "\n",
    "    for i in range(gpu_count):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "\n",
    "        print(f\"--- GPU {i} ---\")\n",
    "        print(f\"Name: {props.name}\")\n",
    "        print(f\"Compute capability: {props.major}.{props.minor}\")\n",
    "        print(f\"Total memory: {bytes_to_mb(props.total_memory):.0f} MB\")\n",
    "\n",
    "        # Architecture details\n",
    "        print(f\"Multiprocessors (SMs): {props.multi_processor_count}\")\n",
    "        print(f\"Max threads per SM: {props.max_threads_per_multi_processor}\")\n",
    "        # print(f\"Max threads per block: {props.max_threads_per_block}\")\n",
    "        print(f\"Warp size: {props.warp_size}\")\n",
    "\n",
    "        # Clock rates\n",
    "        # print(f\"GPU clock rate: {props.clock_rate / 1000:.1f} MHz\")\n",
    "        # print(f\"Memory clock rate: {props.memory_clock_rate / 1000:.1f} MHz\")\n",
    "\n",
    "        # Memory system\n",
    "        # print(f\"Memory bus width: {props.memory_bus_width} bits\")\n",
    "        # print(f\"L2 cache size: {props.l2_cache_size / 1024:.0f} KB\")\n",
    "\n",
    "        # Current memory usage (PyTorch-side)\n",
    "        torch.cuda.set_device(i)\n",
    "        print(f\"Memory allocated: {bytes_to_mb(torch.cuda.memory_allocated(i)):.1f} MB\")\n",
    "        print(f\"Memory reserved : {bytes_to_mb(torch.cuda.memory_reserved(i)):.1f} MB\")\n",
    "\n",
    "        print()\n",
    "\n",
    "else:\n",
    "    print(\"❌ No Nvidia GPU visible to PyTorch (CPU-only mode).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1a422dd-fbbf-49b5-8e71-9253d0ac31d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permission needed to access required GPU device node(s):\n",
      "  - /dev/dri/card0: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card1: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card2: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card3: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card4: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card5: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card6: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card7: Permission denied; owner=root(0):video(44);\n",
      "  - /dev/dri/card8: Permission denied; owner=root(0):video(44);\n",
      "\n",
      "You can try:\n",
      "  • Add your user to the group that owns these devices:\n",
      "      sudo usermod -aG <group> \"$USER\"\n",
      "\n",
      "+------------------------------------------------------------------------------+\n",
      "| AMD-SMI 26.2.0+021c61fc      amdgpu version: 6.16.6   ROCm version: 7.1.1    |\n",
      "| VBIOS version: 00162356                                                      |\n",
      "| Platform: Linux Baremetal                                                    |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| BDF                        GPU-Name | Mem-Uti   Temp   UEC       Power-Usage |\n",
      "| GPU  HIP-ID  OAM-ID  Partition-Mode | GFX-Uti    Fan               Mem-Usage |\n",
      "|=====================================+========================================|\n",
      "| 0000:03:00.0  AMD Radeon PRO W7900D | 0 %      31 °C   0            15/241 W |\n",
      "|   0       0     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:23:00.0  AMD Radeon PRO W7900D | 0 %      32 °C   0            14/241 W |\n",
      "|   1       1     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:43:00.0  AMD Radeon PRO W7900D | 0 %      31 °C   0             9/241 W |\n",
      "|   2       2     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:63:00.0  AMD Radeon PRO W7900D | 0 %      30 °C   0            10/241 W |\n",
      "|   3       3     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:83:00.0  AMD Radeon PRO W7900D | 0 %      30 °C   0             9/241 W |\n",
      "|   4       4     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:a3:00.0  AMD Radeon PRO W7900D | 0 %      31 °C   0            19/241 W |\n",
      "|   5       5     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:c3:00.0  AMD Radeon PRO W7900D | 0 %      32 °C   0            10/241 W |\n",
      "|   6       6     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "|-------------------------------------+----------------------------------------|\n",
      "| 0000:e3:00.0  AMD Radeon PRO W7900D | 0 %      31 °C   0            14/241 W |\n",
      "|   7       7     N/A             N/A | 0 %     20.0 %             26/49136 MB |\n",
      "+-------------------------------------+----------------------------------------+\n",
      "+------------------------------------------------------------------------------+\n",
      "| Processes:                                                                   |\n",
      "|  GPU        PID  Process Name          GTT_MEM  VRAM_MEM  MEM_USAGE     CU % |\n",
      "|==============================================================================|\n",
      "|    0     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    1     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    2     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    3     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    4     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    5     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    6     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "|    7     534014  N/A                     0.0 B     0.0 B      0.0 B  N/A     |\n",
      "+------------------------------------------------------------------------------+\n",
      "Process Name may require elevated permissions.\n"
     ]
    }
   ],
   "source": [
    "!amd-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ec74b-a4b5-435c-8975-657a032d05fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b1da9-5c21-4864-af94-52ca27b1a845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d30422b-a5f7-4cce-95f9-4d44a0a97b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.18\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "937de4ef-34ef-4ce5-9b15-c2b1b69e9d9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-08 15:02:51.832581: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-08 15:02:51.866187: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-02-08 15:02:51.866219: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-02-08 15:02:51.867870: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-02-08 15:02:51.875924: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-08 15:02:52.541450: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[rank: 0] Global seed set to 123\n",
      "Nvidia GPU detected!\n",
      "Total visible GPUs: 1\n",
      "--- GPU 0 ---\n",
      "Name: AMD Radeon PRO W7900D\n",
      "Total memory: 49136 MB\n",
      "it's find only 1 gpus can't do multi gpu\n",
      "still run it's any ways\n",
      "INFO:root:[INFO] Start Inference\n",
      "INFO:root:init valueable: 0.005638s\n",
      "/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n",
      "INFO:mainlogger:LatentVisualDiffusion: Running in v-prediction mode\n",
      "INFO:unifolm_wma.models.diffusion_head.conditional_unet1d:number of parameters: 5.010531e+08\n",
      "INFO:unifolm_wma.models.diffusion_head.conditional_unet1d:number of parameters: 5.010531e+08\n",
      "AE working on z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "INFO:root:Loaded ViT-H-14 model config.\n",
      "INFO:root:Loaded ViT-H-14 model config.\n",
      "./ASC26-Embodied-World-Model-Optimization/ckpts/unifolm_wma_dual.ckpt\n",
      "INFO:root:load models: 31.522963s\n",
      ">>> model checkpoint loaded.\n",
      ">>> Load pre-trained model ...\n",
      "INFO:root:load model checkpoint: 22.106597s\n",
      "INFO:root:***** Configing Data *****\n",
      ">>> Loading all datasets from config\n",
      ">>> Dataset: unitree_z1_stackbox\n",
      "    meta_path: /mnt/ASC1664/unifolm-wma-0-dual/unifolm-world-model-action/examples/world_model_interaction_prompts/unitree_z1_stackbox.csv\n",
      "    transition_dir: /mnt/ASC1664/unifolm-wma-0-dual/unifolm-world-model-action/examples/world_model_interaction_prompts/transitions\n",
      "    data_dir: /mnt/ASC1664/unifolm-wma-0-dual/unifolm-world-model-action/examples/world_model_interaction_prompts\n",
      ">>> unitree_z1_stackbox: 1 data samples loaded.\n",
      ">>> unitree_z1_stackbox: data stats loaded.\n",
      ">>> unitree_z1_stackbox: normalizer initiated.\n",
      ">>> Dataset: unitree_z1_dual_arm_stackbox\n",
      "    meta_path: /mnt/ASC1664/unifolm-wma-0-dual/unifolm-world-model-action/examples/world_model_interaction_prompts/unitree_z1_dual_arm_stackbox.csv\n",
      "    transition_dir: /mnt/ASC1664/unifolm-wma-0-dual/unifolm-world-model-action/examples/world_model_interaction_prompts/transitions\n",
      "    data_dir: /mnt/ASC1664/unifolm-wma-0-dual/unifolm-world-model-action/examples/world_model_interaction_prompts\n",
      ">>> unitree_z1_dual_arm_stackbox: 1 data samples loaded.\n",
      ">>> unitree_z1_dual_arm_stackbox: data stats loaded.\n",
      ">>> unitree_z1_dual_arm_stackbox: normalizer initiated.\n",
      ">>> Dataset: unitree_z1_dual_arm_stackbox_v2\n",
      "    meta_path: /mnt/ASC1664/unifolm-wma-0-dual/unifolm-world-model-action/examples/world_model_interaction_prompts/unitree_z1_dual_arm_stackbox_v2.csv\n",
      "    transition_dir: /mnt/ASC1664/unifolm-wma-0-dual/unifolm-world-model-action/examples/world_model_interaction_prompts/transitions\n",
      "    data_dir: /mnt/ASC1664/unifolm-wma-0-dual/unifolm-world-model-action/examples/world_model_interaction_prompts\n",
      ">>> unitree_z1_dual_arm_stackbox_v2: 1 data samples loaded.\n",
      ">>> unitree_z1_dual_arm_stackbox_v2: data stats loaded.\n",
      ">>> unitree_z1_dual_arm_stackbox_v2: normalizer initiated.\n",
      ">>> Dataset: unitree_z1_dual_arm_cleanup_pencils\n",
      "    meta_path: /mnt/ASC1664/unifolm-wma-0-dual/unifolm-world-model-action/examples/world_model_interaction_prompts/unitree_z1_dual_arm_cleanup_pencils.csv\n",
      "    transition_dir: /mnt/ASC1664/unifolm-wma-0-dual/unifolm-world-model-action/examples/world_model_interaction_prompts/transitions\n",
      "    data_dir: /mnt/ASC1664/unifolm-wma-0-dual/unifolm-world-model-action/examples/world_model_interaction_prompts\n",
      ">>> unitree_z1_dual_arm_cleanup_pencils: 1 data samples loaded.\n",
      ">>> unitree_z1_dual_arm_cleanup_pencils: data stats loaded.\n",
      ">>> unitree_z1_dual_arm_cleanup_pencils: normalizer initiated.\n",
      ">>> Dataset: unitree_g1_pack_camera\n",
      "    meta_path: /mnt/ASC1664/unifolm-wma-0-dual/unifolm-world-model-action/examples/world_model_interaction_prompts/unitree_g1_pack_camera.csv\n",
      "    transition_dir: /mnt/ASC1664/unifolm-wma-0-dual/unifolm-world-model-action/examples/world_model_interaction_prompts/transitions\n",
      "    data_dir: /mnt/ASC1664/unifolm-wma-0-dual/unifolm-world-model-action/examples/world_model_interaction_prompts\n",
      ">>> unitree_g1_pack_camera: 1 data samples loaded.\n",
      ">>> unitree_g1_pack_camera: data stats loaded.\n",
      ">>> unitree_g1_pack_camera: normalizer initiated.\n",
      ">>> Dataset is successfully loaded ...\n",
      "INFO:root:load data: 0.195150s\n",
      ">>> Generate 16 frames under each generation ...\n",
      "INFO:root:set up data: 0.000028s\n",
      "INFO:root:[INFO] Start running Inference\n",
      "INFO:root:get_init_frame_path: 0.000039s\n",
      "INFO:root:mkdir: 0.001095s\n",
      "INFO:root:get_transition_path: 0.000015s\n",
      "DEBUG:h5py._conv:Creating converter from 3 to 5\n",
      "INFO:root:load file h5py: 0.004804s\n",
      "INFO:root:[INFO] start running on loop frame_stride\n",
      "INFO:root:mkdir => save dir: 0.000643s\n",
      "INFO:root:init value: 0.000006s\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IHDR' 16 13\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IDAT' 41 65536\n",
      "INFO:root:PIL open image : 0.012609s\n",
      "INFO:root:create action & state: 0.000250s\n",
      "INFO:root:normalize action - state: 0.000628s\n",
      "INFO:root:spatial_transform: 0.000784s\n",
      "INFO:root:prepare_init_input : 0.015538s\n",
      "INFO:root:init observation: 0.003783s\n",
      "INFO:root:init condition input w/ populate_queues: 0.000016s\n",
      "INFO:root:[INFO] start running on loop n_iter\n",
      "INFO:root:[INFO] start 1/12 n_iter (start with idx:1)\n",
      "INFO:root:get decision model observation: 0.025278s\n",
      ">>> Step 1: generating actions ...\n",
      "INFO:root:[INFO] Step 1: generating actions ...\n",
      "INFO:root:[INFO] IN image_guided_synthesis_sim_mode function\n",
      "INFO:root:init model & noise: 0.000132s\n",
      "INFO:root:permute image: 0.000006s\n",
      "INFO:root:rearrange image: 0.002113s\n",
      "/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/nn/functional.py:6487: UserWarning: Flash Efficient attention on Current AMD GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:309.)\n",
      "  attn_output = scaled_dot_product_attention(\n",
      "/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/nn/functional.py:6487: UserWarning: Mem Efficient attention on Current AMD GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:360.)\n",
      "  attn_output = scaled_dot_product_attention(\n",
      "INFO:root:CLIP Embedded Image: 0.731161s\n",
      "INFO:root:Projector Image model: 0.003965s\n",
      "INFO:root:[INFO] get_latent_z function\n",
      "INFO:root:get_latent_z => rearrange video: 0.000104s\n",
      "INFO:root:get_latent_z => encode_first_stage: 0.146826s\n",
      "INFO:root:get_latent_z => rearrange z: 0.000111s\n",
      "INFO:root:conditioning_key -> repeat: 0.000106s\n",
      "INFO:root:Embedded Prompt: 0.027003s\n",
      "INFO:root:Projector state: 0.000212s\n",
      "INFO:root:Projector action: 0.000147s\n",
      "INFO:root:[INFO] Apply model logic\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ASC1664/unifolm-wma-0-dual_run_workspace/unifolm-world-model-action/scripts/evaluation/world_model_interaction.py\", line 957, in <module>\n",
      "    run_inference(args, gpu_num, rank, \"None\")\n",
      "  File \"/mnt/ASC1664/unifolm-wma-0-dual_run_workspace/unifolm-world-model-action/scripts/evaluation/world_model_interaction.py\", line 680, in run_inference\n",
      "    pred_videos_0, pred_actions, _ = image_guided_synthesis_sim_mode(\n",
      "  File \"/mnt/ASC1664/unifolm-wma-0-dual_run_workspace/unifolm-world-model-action/scripts/evaluation/world_model_interaction.py\", line 451, in image_guided_synthesis_sim_mode\n",
      "    samples, actions, states, intermedia = ddim_sampler.sample(\n",
      "  File \"/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/mnt/ASC1664/unifolm-wma-0-dual/ASC26-Embodied-World-Model-Optimization/src/unifolm_wma/models/samplers/ddim.py\", line 143, in sample\n",
      "    samples, actions, states, intermediates = self.ddim_sampling(\n",
      "  File \"/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/mnt/ASC1664/unifolm-wma-0-dual/ASC26-Embodied-World-Model-Optimization/src/unifolm_wma/models/samplers/ddim.py\", line 257, in ddim_sampling\n",
      "    outs = self.p_sample_ddim(\n",
      "  File \"/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/mnt/ASC1664/unifolm-wma-0-dual/ASC26-Embodied-World-Model-Optimization/src/unifolm_wma/models/samplers/ddim.py\", line 334, in p_sample_ddim\n",
      "    model_output, model_output_action, model_output_state = self.model.apply_model(\n",
      "  File \"/mnt/ASC1664/unifolm-wma-0-dual/ASC26-Embodied-World-Model-Optimization/src/unifolm_wma/models/ddpms.py\", line 1267, in apply_model\n",
      "    x_recon, x_action_recon, x_state_recon = self.model(\n",
      "  File \"/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/mnt/ASC1664/unifolm-wma-0-dual/ASC26-Embodied-World-Model-Optimization/src/unifolm_wma/models/ddpms.py\", line 2473, in forward\n",
      "    out = self.diffusion_model(xc,\n",
      "  File \"/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/mnt/ASC1664/unifolm-wma-0-dual/ASC26-Embodied-World-Model-Optimization/src/unifolm_wma/modules/networks/wma_model.py\", line 835, in forward\n",
      "    a_y = self.action_unet(x_action, timesteps[:ba], hs_a,\n",
      "  File \"/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/mnt/ASC1664/unifolm-wma-0-dual/ASC26-Embodied-World-Model-Optimization/src/unifolm_wma/models/diffusion_head/conditional_unet1d.py\", line 688, in forward\n",
      "    x = resnet(x, cur_global_feature)\n",
      "  File \"/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/mnt/ASC1664/unifolm-wma-0-dual/ASC26-Embodied-World-Model-Optimization/src/unifolm_wma/models/diffusion_head/conditional_unet1d.py\", line 271, in forward\n",
      "    embed = self.cond_encoder(cond)\n",
      "  File \"/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1958, in __getattr__\n",
      "    if name in _buffers:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python unifolm-world-model-action/scripts/evaluation/world_model_interaction.py \\\n",
    "        --seed $123 \\\n",
    "        --ckpt_path \"./ASC26-Embodied-World-Model-Optimization/ckpts/unifolm_wma_dual.ckpt\" \\\n",
    "        --config \"./unifolm-world-model-action/configs/inference/world_model_interaction.yaml\" \\\n",
    "        --savedir \"./results/run/testing/unitree_z1_stackbox\" \\\n",
    "        --bs 1 --height 320 --width 512 \\\n",
    "        --unconditional_guidance_scale 1.0 \\\n",
    "        --ddim_steps 50 \\\n",
    "        --ddim_eta 1.0 \\\n",
    "        --prompt_dir \"./unifolm-world-model-action/examples/world_model_interaction_prompts\" \\\n",
    "        --dataset \"unitree_z1_stackbox\" \\\n",
    "        --video_length 16 \\\n",
    "        --frame_stride 4 \\\n",
    "        --n_action_steps 16 \\\n",
    "        --exe_steps 16 \\\n",
    "        --n_iter 12 \\\n",
    "        --timestep_spacing 'uniform_trailing' \\\n",
    "        --guidance_rescale 0.7 \\\n",
    "        --perframe_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c09e5e1-5da2-4eb5-83eb-693b6688e623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
