Switching to group 'render' and re-executing...
True
Checking GPU Availability...
Torch version: 2.9.1+rocm7.1.1.git351ff442
Is ROCm/CUDA available?: True
Device count: 1
/var/spool/slurm/slurmd/job02886/slurm_script: line 44: module: command not found
-------------------------------------------
Processing dataset: unitree_z1_stackbox
2026-02-07 15:06:25.959536: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-02-07 15:06:25.996016: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2026-02-07 15:06:25.996079: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2026-02-07 15:06:25.997963: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2026-02-07 15:06:26.006998: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2026-02-07 15:06:26.751947: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[rank: 0] Global seed set to 123
INFO:root:[INFO] Start Inference
INFO:root:init valueable: 0.008439s
/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
INFO:mainlogger:LatentVisualDiffusion: Running in v-prediction mode
WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.3.1+cu121 with CUDA 1201 (you have 2.9.1+rocm7.1.1.git351ff442)
    Python  3.10.14 (you have 3.10.18)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/xformers/ops/swiglu_op.py:128: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(cls, ctx, x, w1, b1, w2, b2, w3, b3):
/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/xformers/ops/swiglu_op.py:149: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(cls, ctx, dx5):
INFO:unifolm_wma.models.diffusion_head.conditional_unet1d:number of parameters: 5.010531e+08
INFO:unifolm_wma.models.diffusion_head.conditional_unet1d:number of parameters: 5.010531e+08
AE working on z of shape (1, 4, 32, 32) = 4096 dimensions.
INFO:root:Loaded ViT-H-14 model config.
INFO:root:Loaded ViT-H-14 model config.
/mnt/ASC1664/unifolm-wma-0-dual_run_workspace/ASC26-Embodied-World-Model-Optimization/ckpts/unifolm_wma_dual.ckpt
INFO:root:load models: 28.891913s
>>> model checkpoint loaded.
>>> Load pre-trained model ...
INFO:root:load model checkpoint: 13.834104s
INFO:root:***** Configing Data *****
>>> unitree_z1_stackbox: 1 data samples loaded.
>>> unitree_z1_stackbox: data stats loaded.
>>> unitree_z1_stackbox: normalizer initiated.
>>> unitree_z1_dual_arm_stackbox: 1 data samples loaded.
>>> unitree_z1_dual_arm_stackbox: data stats loaded.
>>> unitree_z1_dual_arm_stackbox: normalizer initiated.
>>> unitree_z1_dual_arm_stackbox_v2: 1 data samples loaded.
>>> unitree_z1_dual_arm_stackbox_v2: data stats loaded.
>>> unitree_z1_dual_arm_stackbox_v2: normalizer initiated.
>>> unitree_z1_dual_arm_cleanup_pencils: 1 data samples loaded.
>>> unitree_z1_dual_arm_cleanup_pencils: data stats loaded.
>>> unitree_z1_dual_arm_cleanup_pencils: normalizer initiated.
>>> unitree_g1_pack_camera: 1 data samples loaded.
>>> unitree_g1_pack_camera: data stats loaded.
>>> unitree_g1_pack_camera: normalizer initiated.
>>> Dataset is successfully loaded ...
INFO:root:load data: 0.073478s
>>> Generate 16 frames under each generation ...
INFO:root:set up data: 0.000026s
INFO:root:[INFO] Start running Inference
INFO:root:get_init_frame_path: 0.000050s
INFO:root:mkdir: 0.000425s
INFO:root:get_transition_path: 0.000020s
DEBUG:h5py._conv:Creating converter from 3 to 5
INFO:root:load file h5py: 0.007213s
INFO:root:[INFO] start running on loop frame_stride
INFO:root:mkdir => save dir: 0.000075s
INFO:root:init value: 0.000010s
DEBUG:PIL.PngImagePlugin:STREAM b'IHDR' 16 13
DEBUG:PIL.PngImagePlugin:STREAM b'IDAT' 41 65536
INFO:root:PIL open image : 0.012566s
INFO:root:create action & state: 0.000309s
INFO:root:normalize action - state: 0.000719s
INFO:root:spatial_transform: 0.001021s
INFO:root:prepare_init_input : 0.037262s
INFO:root:init observation: 0.001908s
INFO:root:init condition input w/ populate_queues: 0.000016s
INFO:root:[INFO] start running on loop n_iter
INFO:root:[INFO] start 1/12 n_iter (start with idx:1)
INFO:root:get decision model observation: 0.017519s
>>> Step 1: generating actions ...
INFO:root:[INFO] Step 1: generating actions ...
INFO:root:[INFO] IN image_guided_synthesis_sim_mode function
INFO:root:init model & noise: 0.000487s
INFO:root:permute image: 0.000037s
INFO:root:rearrange image: 0.001426s
/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/nn/functional.py:6487: UserWarning: Flash Efficient attention on Current AMD GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:309.)
  attn_output = scaled_dot_product_attention(
/mnt/ASC1664/miniconda3/envs/unifolm-wma/lib/python3.10/site-packages/torch/nn/functional.py:6487: UserWarning: Mem Efficient attention on Current AMD GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:360.)
  attn_output = scaled_dot_product_attention(
INFO:root:CLIP Embedded Image: 0.634646s
INFO:root:Projector Image model: 0.004039s
INFO:root:[INFO] get_latent_z function
INFO:root:get_latent_z => rearrange video: 0.000145s
INFO:root:get_latent_z => encode_first_stage: 0.131846s
INFO:root:get_latent_z => rearrange z: 0.000132s
INFO:root:conditioning_key -> repeat: 0.000133s
INFO:root:Embedded Prompt: 0.016955s
INFO:root:Projector state: 0.000274s
INFO:root:Projector action: 0.000201s
INFO:root:[INFO] Apply model logic
INFO:root:[INFO] DDIMSampler.sample
INFO:root:prepare input of ddim_sampling: 0.022317s
INFO:root:prepare input of feeding: 0.006567s
INFO:root:[INFO] ========= Iteration [999 979 959 939 919 899 879 859 839 819 799 779 759 739 719 699 679 659
 639 619 599 579 559 539 519 499 479 459 439 419 399 379 359 339 319 299
 279 259 239 219 199 179 159 139 119  99  79  59  39  19] in total =========
INFO:root:[INFO] ========= Iteration 0/[999 979 959 939 919 899 879 859 839 819 799 779 759 739 719 699 679 659
 639 619 599 579 559 539 519 499 479 459 439 419 399 379 359 339 319 299
 279 259 239 219 199 179 159 139 119  99  79  59  39  19] =========
INFO:root:[INFO] p_sample_ddim
INFO:root:unconditional_conditioning: 3.317992s
INFO:root:predict_eps_from_z_and_v: 0.011587s
INFO:root:alphas_cumprod: 0.000002s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.000828s
INFO:root:pred_x0 : 0.000119s
INFO:root:use_dynamic_rescale: 0.000314s
INFO:root:tensor sqrt.quantize: 0.000164s
INFO:root:noise_like: 0.000081s
INFO:root:math apply: 0.000040s
INFO:root:[INFO] ========= Iteration 1/[999 979 959 939 919 899 879 859 839 819 799 779 759 739 719 699 679 659
 639 619 599 579 559 539 519 499 479 459 439 419 399 379 359 339 319 299
 279 259 239 219 199 179 159 139 119  99  79  59  39  19] =========
INFO:root:[INFO] p_sample_ddim
INFO:root:unconditional_conditioning: 3.056390s
INFO:root:predict_eps_from_z_and_v: 0.000104s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.000327s
INFO:root:pred_x0 : 0.000097s
INFO:root:use_dynamic_rescale: 0.000281s
INFO:root:tensor sqrt.quantize: 0.000102s
INFO:root:noise_like: 0.000079s
INFO:root:math apply: 0.000038s
INFO:root:[INFO] ========= Iteration 2/[999 979 959 939 919 899 879 859 839 819 799 779 759 739 719 699 679 659
 639 619 599 579 559 539 519 499 479 459 439 419 399 379 359 339 319 299
 279 259 239 219 199 179 159 139 119  99  79  59  39  19] =========
INFO:root:[INFO] p_sample_ddim
INFO:root:unconditional_conditioning: 3.050513s
INFO:root:predict_eps_from_z_and_v: 0.000097s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.000498s
INFO:root:pred_x0 : 0.000130s
INFO:root:use_dynamic_rescale: 0.000253s
INFO:root:tensor sqrt.quantize: 0.000120s
INFO:root:noise_like: 0.000078s
INFO:root:math apply: 0.000045s
INFO:root:[INFO] ========= Iteration 3/[999 979 959 939 919 899 879 859 839 819 799 779 759 739 719 699 679 659
 639 619 599 579 559 539 519 499 479 459 439 419 399 379 359 339 319 299
 279 259 239 219 199 179 159 139 119  99  79  59  39  19] =========
INFO:root:[INFO] p_sample_ddim
INFO:root:unconditional_conditioning: 3.065032s
INFO:root:predict_eps_from_z_and_v: 0.000099s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.000180s
INFO:root:pred_x0 : 0.000091s
INFO:root:use_dynamic_rescale: 0.000250s
INFO:root:tensor sqrt.quantize: 0.000091s
INFO:root:noise_like: 0.000069s
INFO:root:math apply: 0.000040s
INFO:root:[INFO] ========= Iteration 4/[999 979 959 939 919 899 879 859 839 819 799 779 759 739 719 699 679 659
 639 619 599 579 559 539 519 499 479 459 439 419 399 379 359 339 319 299
 279 259 239 219 199 179 159 139 119  99  79  59  39  19] =========
INFO:root:[INFO] p_sample_ddim
INFO:root:unconditional_conditioning: 3.049304s
INFO:root:predict_eps_from_z_and_v: 0.000105s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000000s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.000177s
INFO:root:pred_x0 : 0.000089s
INFO:root:use_dynamic_rescale: 0.000243s
INFO:root:tensor sqrt.quantize: 0.000092s
INFO:root:noise_like: 0.000071s
INFO:root:math apply: 0.000040s
INFO:root:[INFO] ========= Iteration 5/[999 979 959 939 919 899 879 859 839 819 799 779 759 739 719 699 679 659
 639 619 599 579 559 539 519 499 479 459 439 419 399 379 359 339 319 299
 279 259 239 219 199 179 159 139 119  99  79  59  39  19] =========
INFO:root:[INFO] p_sample_ddim
INFO:root:unconditional_conditioning: 3.060420s
INFO:root:predict_eps_from_z_and_v: 0.000095s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.000178s
INFO:root:pred_x0 : 0.000089s
INFO:root:use_dynamic_rescale: 0.000242s
INFO:root:tensor sqrt.quantize: 0.000101s
INFO:root:noise_like: 0.000077s
INFO:root:math apply: 0.000039s
INFO:root:[INFO] ========= Iteration 6/[999 979 959 939 919 899 879 859 839 819 799 779 759 739 719 699 679 659
 639 619 599 579 559 539 519 499 479 459 439 419 399 379 359 339 319 299
 279 259 239 219 199 179 159 139 119  99  79  59  39  19] =========
INFO:root:[INFO] p_sample_ddim
INFO:root:unconditional_conditioning: 3.058802s
INFO:root:predict_eps_from_z_and_v: 0.000111s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.000825s
INFO:root:pred_x0 : 0.000127s
INFO:root:use_dynamic_rescale: 0.000260s
INFO:root:tensor sqrt.quantize: 0.000118s
INFO:root:noise_like: 0.000084s
INFO:root:math apply: 0.000039s
INFO:root:[INFO] ========= Iteration 7/[999 979 959 939 919 899 879 859 839 819 799 779 759 739 719 699 679 659
 639 619 599 579 559 539 519 499 479 459 439 419 399 379 359 339 319 299
 279 259 239 219 199 179 159 139 119  99  79  59  39  19] =========
INFO:root:[INFO] p_sample_ddim
INFO:root:unconditional_conditioning: 3.047717s
INFO:root:predict_eps_from_z_and_v: 0.000104s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.001683s
INFO:root:pred_x0 : 0.000122s
INFO:root:use_dynamic_rescale: 0.000259s
INFO:root:tensor sqrt.quantize: 0.000104s
INFO:root:noise_like: 0.000085s
INFO:root:math apply: 0.000041s
INFO:root:[INFO] ========= Iteration 8/[999 979 959 939 919 899 879 859 839 819 799 779 759 739 719 699 679 659
 639 619 599 579 559 539 519 499 479 459 439 419 399 379 359 339 319 299
 279 259 239 219 199 179 159 139 119  99  79  59  39  19] =========
INFO:root:[INFO] p_sample_ddim
INFO:root:unconditional_conditioning: 3.060010s
INFO:root:predict_eps_from_z_and_v: 0.000097s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.000353s
INFO:root:pred_x0 : 0.000183s
INFO:root:use_dynamic_rescale: 0.000250s
INFO:root:tensor sqrt.quantize: 0.000109s
INFO:root:noise_like: 0.000074s
INFO:root:math apply: 0.000042s
INFO:root:[INFO] ========= Iteration 9/[999 979 959 939 919 899 879 859 839 819 799 779 759 739 719 699 679 659
 639 619 599 579 559 539 519 499 479 459 439 419 399 379 359 339 319 299
 279 259 239 219 199 179 159 139 119  99  79  59  39  19] =========
INFO:root:[INFO] p_sample_ddim
INFO:root:unconditional_conditioning: 3.062562s
INFO:root:predict_eps_from_z_and_v: 0.000135s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.001217s
INFO:root:pred_x0 : 0.000200s
INFO:root:use_dynamic_rescale: 0.000257s
INFO:root:tensor sqrt.quantize: 0.000117s
INFO:root:noise_like: 0.000080s
INFO:root:math apply: 0.000040s
INFO:root:[INFO] ========= Iteration 10/[999 979 959 939 919 899 879 859 839 819 799 779 759 739 719 699 679 659
 639 619 599 579 559 539 519 499 479 459 439 419 399 379 359 339 319 299
 279 259 239 219 199 179 159 139 119  99  79  59  39  19] =========
INFO:root:[INFO] p_sample_ddim
INFO:root:unconditional_conditioning: 3.053508s
INFO:root:predict_eps_from_z_and_v: 0.000106s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.001746s
INFO:root:pred_x0 : 0.000202s
INFO:root:use_dynamic_rescale: 0.000260s
INFO:root:tensor sqrt.quantize: 0.000106s
INFO:root:noise_like: 0.000076s
INFO:root:math apply: 0.000039s
INFO:root:[INFO] ========= Iteration 11/[999 979 959 939 919 899 879 859 839 819 799 779 759 739 719 699 679 659
 639 619 599 579 559 539 519 499 479 459 439 419 399 379 359 339 319 299
 279 259 239 219 199 179 159 139 119  99  79  59  39  19] =========
INFO:root:[INFO] p_sample_ddim
INFO:root:unconditional_conditioning: 3.052846s
INFO:root:predict_eps_from_z_and_v: 0.000100s
INFO:root:alphas_cumprod: 0.000001s
INFO:root:alphas_cumprod_prev: 0.000001s
INFO:root:sqrt_one_minus_alphas_cumprod: 0.000001s
INFO:root:ddim_sigmas_for_original_num_steps: 0.000001s
INFO:root:create empty tensor : 0.000183s
INFO:root:pred_x0 : 0.000093s
INFO:root:use_dynamic_rescale: 0.000253s
INFO:root:tensor sqrt.quantize: 0.000102s
INFO:root:noise_like: 0.000077s
INFO:root:math apply: 0.000039s
INFO:root:[INFO] ========= Iteration 12/[999 979 959 939 919 899 879 859 839 819 799 779 759 739 719 699 679 659
 639 619 599 579 559 539 519 499 479 459 439 419 399 379 359 339 319 299
 279 259 239 219 199 179 159 139 119  99  79  59  39  19] =========
INFO:root:[INFO] p_sample_ddim
slurmstepd-wx-ms-w7900d-0032: error: *** JOB 2886 ON wx-ms-w7900d-0032 CANCELLED AT 2026-02-07T15:07:50 ***
